{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ac4e3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# 시각화가 외부 윈도우가 아닌 현재의 노트북 내에서 보이도록 설정.\n",
    "%matplotlib inline\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 신경망 초기화하기\n",
    "    def __init__(self, _inputNodes, _hiddenNodes, _outputNodes, _learningRate):\n",
    "        '''\n",
    "            하나의 클래스에 신경망의 크기를 전달함으로써 신경망 생성이 가능하며,\n",
    "            마찬가지로 학습률(learning rate)도 전달이 가능하다.\n",
    "        '''\n",
    "        \n",
    "        self.i_nodes = _inputNodes\n",
    "        self.h_nodes = _hiddenNodes\n",
    "        self.o_nodes = _outputNodes\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        \n",
    "        # 신경망에서 가장 중요한 부분이 바로 연결 노드의 가중치이다.\n",
    "        # 가중치는 전파시 전달되는 신호와 역전파 시 오차를 계산하는 데 쓰이며, \n",
    "        # 이를 통해 신경망을 개선하는 역할을 수행한다.\n",
    "\n",
    "        # 가중치는 행렬로 간결하게 표현될 수 있다.\n",
    "        # 각각의 가중치는 임의의 작은 값으로 초기화 한다.\n",
    "\n",
    "        # 1. (은닉 노드 x 입력 노드)의 크기를 갖는 입력 계층과 은닉 계층 사이의 가중치의 행렬\n",
    "        # W(input_hidden)\n",
    "        \n",
    "        # 2. (출력노드 x 은닉 노드)의 크기를 갖는 은닉 계층과 출력 계층 사이의 가중치의 행렬\n",
    "        # W(hidden_output)\n",
    "\n",
    "        # numpy를 이용해서 0과 1 사이의 임의로 선택한 값을 원소로 가지는 행렬을 생성.\n",
    "        # 이 행렬의 크기는 (행 x 열)\n",
    "\n",
    "        # input -> hidden\n",
    "        # self.wih = (np.random.rand(self.h_nodes, self.i_nodes) - 0.5)\n",
    "\n",
    "        # hidden -> output\n",
    "        # self.who = (np.random.rand(self.o_nodes, self.h_nodes) - 0.5)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        \n",
    "        # 가중치를 임의의 값으로 초기화하는 더 정교한 방법이 있음.\n",
    "        # 이 경우, 가중치는 0을 중심으로 하여 1/sqrt(들어오는 연결 노드의 개수)의 표준 편차를 갖는\n",
    "        # 정규분포에 따라 구하도록 한다.\n",
    "        # numpy의 numpy.random.normal() 함수를 활용하면 이를 쉽게 구현할 수 있다.\n",
    "        # 이 변수에 필요한 매개변수는 정규분포의 중심, 표준편차, numpy 행렬이다.\n",
    "        \n",
    "        # input -> hidden\n",
    "        # Python에서 노드로 들어오는 연결 노드의 개수에 루트를 씌우고 역수를 취한 표준편차는 파이썬의 문법으로 아래와 같이 표현됨.\n",
    "        # 1. 정규분포의 중심은 0.0\n",
    "        # 2. 표준편차\n",
    "        # 3. 우리가 원하는 numpy 행렬\n",
    "        self.wih = np.random.normal(0.0, pow(self.i_nodes, -0.5), (self.h_nodes, self.i_nodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.h_nodes, -0.5), (self.o_nodes, self.h_nodes))\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        \n",
    "        # 학습률(learning rate)\n",
    "        self.lr = _learningRate\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        # 활성화 함수\n",
    "        # 활성화 함수에 약간의 변화를 주거나, 아니면 때로는 다른 활성화 함수로 교체하는 경우가 있을 수 있으므로,\n",
    "        # 활성화 함수를 신경망 객체의 초기화 부분에 정의해 두는 것이 좋다.\n",
    "        \n",
    "        # lambda 함수로 전달받은 인자 x에 대하여 scipy.special.expit(시그모이드 함수)에 x를 넣은 값을 return한다.\n",
    "        # 일종의 anonymous function이며, activation_function에 할당된 것이다.\n",
    "        self.activation_function = lambda x: scipy.special.expit(x) \n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    # 신경망 학습시키기\n",
    "    def train(self, _inputs_list, _targets_list):\n",
    "        '''\n",
    "            train 함수에는 targets_list라는 매개변수가 있는데,\n",
    "            이 매개변수가 없이는 신경망을 제대로 학습시킬 수 없다.\n",
    "        '''\n",
    "\n",
    "        # 학습에는 두 가지 단계가 있다. \n",
    "        # 1) 첫 번째 단계는 query() 함수와 마찬가지로 출력 값을 계산해내는 단계이다.\n",
    "        # 2) 두 번째 단계는 가중치가 어떻게 업데이트되어야 하는지 알려주기 위해 오차를 역전파 하는 단계이다.\n",
    "        \n",
    "        # 입력 리스트를 2차원의 행렬로 변환\n",
    "        inputs = np.array(_inputs_list, ndmin=2).T # ndmin은 matrix의 차원을 의미함.\n",
    "        targets = np.array(_targets_list, ndmin=2).T # T는 transpose\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = np.dot(self.wih, inputs) # self.wih : input -> hidden의 weight(가중치)\n",
    "        \n",
    "        # 은닉 계층에서 나가는 신호를 계산\n",
    "        # activiation function인 sigmoid를 거쳐서 값을 0~1 사이의 값으로 변환\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) \n",
    "        \n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        # 학습 데이터에 의해 제공되는 실제 값과 우리가 계산한 결과 값 간의 차이를 통해 오차를 계산한다.\n",
    "        # 즉, 오차는 (실제 값 행렬 - 계산 값 행렬)이다.\n",
    "        \n",
    "        # 은닉 계층과 최종 계층 간의 가중치는 output_errors\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # 은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        # self.lr : 학습률. 식의 나머지 부분 전체에 곱해진다.\n",
    "        # final_outputs * (1.0 - final_outputs) : 오차의 다음 계층으로부터의 시그모이드\n",
    "        # np.transpose(hidden_outputs) : 이전 계층으로부터의 결과값을 전치한 것.\n",
    "        \n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "    \n",
    "        pass\n",
    "    \n",
    "    # 신경망에 질의하기\n",
    "    def query(self, _inputs_list):\n",
    "        '''\n",
    "            신경망으로 들어오는 입력을 받아 출력을 반환한다.\n",
    "            입력 계층부터 은닉 계층을 거쳐 최종 출력 계층까지 수행한다.\n",
    "            또한, 신호는 은닉 노드와 출력 노드로 전달될 때 가중치 연산과 활성화 함수 적용을 거친다.\n",
    "        '''\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "        \n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        \n",
    "        # 우선 1차원 array로 데이터를 넘기면, np.array를 통해서\n",
    "        # 2차원 matrix로 변환하는 것으로 생각하면 될듯.\n",
    "        inputs = np.array(_inputs_list, ndmin=2).T # 뒤에 붙은 T는 transpose?\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        \n",
    "        # numpy의 dot 함수를 통해서 은닉 계층의 각 노드로 들어오는 신호를 계산한다.\n",
    "        # 내적을 이용하면 입력 계층이나 은닉 계층의 노드 수가 달라지더라도 코드를 다시 작성할 필요가 없다.\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        # 은닉 계층에서 나가는 신호를 계산\n",
    "        \n",
    "        # 이제 은닉계층으로부터 나오는 신호를 구하려면, 시그모이드 함수를 적용하는 일만 하면 된다.\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # activation_function을 거치면, 은닉 계층에서 나가는 신호들은 hidden_outputs에 저장된다.\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        \n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        return final_outputs\n",
    "\n",
    "        # 이후에 노드의 개수(hidden_layer)가 많아지면 for loop을 돌려서 학습시키는 것인듯?\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2adda71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 784\n",
    "hidden_nodes = 500\n",
    "output_nodes = 10\n",
    "\n",
    "# 학습률은 0.3으로 정의\n",
    "learning_rate = 0.2\n",
    "\n",
    "# 신경망의 인스턴스를 생성\n",
    "n = NeuralNetwork(_inputNodes=input_nodes, _hiddenNodes=hidden_nodes, _outputNodes=output_nodes, _learningRate=learning_rate)\n",
    "\n",
    "# len(n.data_list)\n",
    "\n",
    "# 학습 데이터 파일 읽기\n",
    "training_data_file = open(\"./mnist_train.csv\", 'r')\n",
    "\n",
    "# 현재 파일의 크기가 그렇게 크지 않으므로, readlines()로 한 번에 데이터를 메모리로 올린다.\n",
    "# 하지만 학습 데이터의 크기가 클 경우, readline()을 이용하여 한 행씩 데이터를 올리는 것이 좋다.\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "965eee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    np.asfarray를 이용해 문자열을 실수로 변환.\\n    이때, all_values[1:]을 이용해서 첫 번째 원소를 제외한 나머지 값만을 취한다.\\n    이렇게 얻은 값을 28x28의 matrix로 변환한다.\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_values = n.data_list[0].split(',') # 레이블 분리\n",
    "\n",
    "'''\n",
    "    np.asfarray를 이용해 문자열을 실수로 변환.\n",
    "    이때, all_values[1:]을 이용해서 첫 번째 원소를 제외한 나머지 값만을 취한다.\n",
    "    이렇게 얻은 값을 28x28의 matrix로 변환한다.\n",
    "'''\n",
    "\n",
    "# image_array = np.asfarray(all_values[1:]).reshape((28, 28))\n",
    "# matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f8221720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n데이터를 학습시킬 때, 입력 데이터와 출력 데이터의 값들이 적절한 형태를 가져\\n활성화 함수의 수용 범위 내에 있게 되면 신경망은 더 잘 동작하게 된다.\\n이에 따라, 색상 값이 0.01 ~ 1.0 사이의 값을 갖도록 만든다.\\n이때 입력 값이 0이 되면 가중치가 사라지게 되므로, 입력의 하한선은 0.01, 상한선은 1.0으로 설정한다.\\n'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "데이터를 학습시킬 때, 입력 데이터와 출력 데이터의 값들이 적절한 형태를 가져\n",
    "활성화 함수의 수용 범위 내에 있게 되면 신경망은 더 잘 동작하게 된다.\n",
    "이에 따라, 색상 값이 0.01 ~ 1.0 사이의 값을 갖도록 만든다.\n",
    "이때 입력 값이 0이 되면 가중치가 사라지게 되므로, 입력의 하한선은 0.01, 상한선은 1.0으로 설정한다.\n",
    "'''\n",
    "\n",
    "# scaled_input = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "# scaled_input = scaled_input.reshape((28, 28))\n",
    "# print(scaled_input)\n",
    "# matplotlib.pyplot.imshow(scaled_input, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e123944",
   "metadata": {},
   "source": [
    "- - -\n",
    "우리가 Activation Function으로 사용하는 로지스틱 함수는 값의 범위가 0.0 ~ 1.0이다.   \n",
    "이때 0.0과 1.0에는 무한히 접근만 할 뿐, 실제 0.0이나 1.0이 될 수는 없다.   \n",
    "그러므로 학습 시에 우리의 결과 값의 범위를 조정해주어야 한다.   \n",
    "   \n",
    "우리가 신경망의 학습 과정에 바라는 것은 최종적으로 0~9 사이의 숫자를 분류해 내는 것이다.   \n",
    "그러므로, 우리는 0~9를 분류해 낼 10개의 노드가 필요하다. 각 노드는 가능한 결과 값. 즉, 각 레이블에 해당할 것이다.   \n",
    "(활성화 함수는 0.0과 1.0에 점근하기 때문에, 절대로 각 노드들이 0.0이라는 값을 가질 수는 없고, 무한히 가까운 값을 가짐)   \n",
    "   \n",
    "- - - \n",
    "   \n",
    "만약 학습 데이터의 레이블이 5라면, 우리는 결과 값 행렬을 만들 때   \n",
    "5에 상응하는 노드 외에는 작은 값을 갖도록 행렬을 구성할 필요가 있다.   \n",
    "> ex : [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
    "   \n",
    "그런데, 앞에서 활성화 함수가 도달할 수 없는 0과 1이라는 값을 사용하게 되면 큰 값의 가중치를 통해 신경망이 포화된다.   \n",
    "그러므로, 값의 범위를 0.01 ~ 0.99 등과 같이 적용하는 것이 좋다.   \n",
    "> ex : [0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01]   \n",
    "- - -\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e32b9c",
   "metadata": {},
   "source": [
    "# 신경망 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "af9d1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    onodes = 10 # 10개의 노드를 가지기 때문에 output node를 10 개 생성\n",
    "    targets = np.zeros(onodes) + 0.01 # 최소 값을 유지하기 위해 값이 모두 0인 1x10의 리스트를 만들고, 최소값 설정 \n",
    "    targets[int(all_values[0])] = 0.99 # 레이블을 떼와서, 해당 레이블에 매칭되는 노드의 값을 0.99로 만들어 준다.\n",
    "'''\n",
    "\n",
    "# 반복 횟수(epoch) 설정\n",
    "epochs = 2\n",
    "\n",
    "for e in range(epochs):\n",
    "    # 학습 데이터에서 한 row를 record라고 함.\n",
    "    for record in training_data_list:\n",
    "        # 레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',')\n",
    "        \n",
    "        # 입력 값의 범위와 값 조정\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        # 결과 값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f3b3917",
   "metadata": {},
   "source": [
    "### 은닉 노드의 개수 선택   \n",
    "* 현재까지 은닉 노드를 몇 개로 해야 할지 결정하는 데 대한 완벽한 방법론은 존재하지 않는다.   \n",
    "   \n",
    "    그러므로 현재로서 최선의 접근 방법은 우리가 해결해야 하는 문제에서 최적의 설정을 찾을 때까지   \n",
    "    실험을 반복하며 그것을 찾아내는 것이다.   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f0bddca",
   "metadata": {},
   "source": [
    "# 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4e419ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = open('./mnist_test.csv', 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "048357bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# get the first test record\n",
    "all_values = test_data_list[0].split(',')\n",
    "\n",
    "# print the label\n",
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1890eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21698df7250>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = np.asfarray(all_values[1:]).reshape((28, 28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "24c5dfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00686683],\n",
       "       [0.01301052],\n",
       "       [0.01791198],\n",
       "       [0.00221884],\n",
       "       [0.00292211],\n",
       "       [0.00210138],\n",
       "       [0.00420705],\n",
       "       [0.98539431],\n",
       "       [0.006177  ],\n",
       "       [0.00116417]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad93d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9537\n"
     ]
    }
   ],
   "source": [
    "# 신경망 테스트\n",
    "\n",
    "# 신경망의 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    "\n",
    "# 테스트 데이터 모음 내의 모든 레코드 탐색\n",
    "for record in test_data_list:\n",
    "    # 레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    \n",
    "    # 정답은 첫 번째 값\n",
    "    correct_label = int(all_values[0])\n",
    "        \n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    # 신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    \n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = np.argmax(outputs)\n",
    "    \n",
    "    # print(correct_label, \"correct label\")\n",
    "    # print(label, \"network's answer\")\n",
    "    \n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    if (label == correct_label):\n",
    "        # 정답인 경우 성적표에 1을 더함\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # 정답이 아닌 경우 성적표에 0을 더함\n",
    "        scorecard.append(0)\n",
    "        \n",
    "    pass\n",
    "\n",
    "# np.array VS np.asarray\n",
    "# 두 방식은 구조적으로는 모두 동일하나, array는 copy=True인 반면, asarray는 copy=False이다.\n",
    "# 즉, array를 다른 변수에 할당하고 원본을 변경하면 array의 copy 본은 변겨외지 않지만, (deep copy)\n",
    "# asarray의 경우 원본이 변경될 경우 asarray의 복사본까지 변경된다. (shallow copy)\n",
    "\n",
    "scorecard_array = np.asarray(scorecard) # 내부의 값들을 \n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
